{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   contour_points  amount_contours     rect_area  hull_area  \\\n0             676                3  20729.545245    14977.0   \n1            1725                3  65025.000000    65025.0   \n2             514                2  18142.000000    14201.0   \n3             492               83   6807.694670     4847.5   \n4             988                5  54314.985718    33316.0   \n\n   approximation_area  contour_perimeters  corners  harris_corners  \\\n0             10152.5          789.494509       53             901   \n1             48154.5         1847.192994       92            1582   \n2             11280.5          561.220343       62             305   \n3              1323.5          598.867093       52              15   \n4             25395.5         1076.641697       54            1504   \n\n   ratio_wide_length  contour_length_area_ratio  \\\n0           3.399329                   0.077310   \n1           1.000000                   0.038508   \n2           0.487047                   0.049727   \n3           0.124905                   0.447584   \n4           1.197183                   0.042451   \n\n   contour_length_rect_area_ratio  contour_length_hull_area_ratio  \\\n0                        0.038085                        0.052714   \n1                        0.028407                        0.028407   \n2                        0.030935                        0.039520   \n3                        0.087969                        0.123541   \n4                        0.019822                        0.032316   \n\n   contour_rect_length_ratio  contour_hull_length_ratio    extent  solidity  \\\n0                   1.149038                   1.318301  0.492630  0.681845   \n1                   1.810974                   1.810974  0.737693  0.737693   \n2                   0.977736                   1.134376  0.622092  0.794733   \n3                   1.140181                   1.214194  0.196542  0.276019   \n4                   1.150258                   1.313623  0.466943  0.761256   \n\n   hull_rectangle_ratio  labels  \n0              0.722495       0  \n1              1.000000       0  \n2              0.782769       0  \n3              0.712062       0  \n4              0.613385       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contour_points</th>\n      <th>amount_contours</th>\n      <th>rect_area</th>\n      <th>hull_area</th>\n      <th>approximation_area</th>\n      <th>contour_perimeters</th>\n      <th>corners</th>\n      <th>harris_corners</th>\n      <th>ratio_wide_length</th>\n      <th>contour_length_area_ratio</th>\n      <th>contour_length_rect_area_ratio</th>\n      <th>contour_length_hull_area_ratio</th>\n      <th>contour_rect_length_ratio</th>\n      <th>contour_hull_length_ratio</th>\n      <th>extent</th>\n      <th>solidity</th>\n      <th>hull_rectangle_ratio</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>676</td>\n      <td>3</td>\n      <td>20729.545245</td>\n      <td>14977.0</td>\n      <td>10152.5</td>\n      <td>789.494509</td>\n      <td>53</td>\n      <td>901</td>\n      <td>3.399329</td>\n      <td>0.077310</td>\n      <td>0.038085</td>\n      <td>0.052714</td>\n      <td>1.149038</td>\n      <td>1.318301</td>\n      <td>0.492630</td>\n      <td>0.681845</td>\n      <td>0.722495</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1725</td>\n      <td>3</td>\n      <td>65025.000000</td>\n      <td>65025.0</td>\n      <td>48154.5</td>\n      <td>1847.192994</td>\n      <td>92</td>\n      <td>1582</td>\n      <td>1.000000</td>\n      <td>0.038508</td>\n      <td>0.028407</td>\n      <td>0.028407</td>\n      <td>1.810974</td>\n      <td>1.810974</td>\n      <td>0.737693</td>\n      <td>0.737693</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>514</td>\n      <td>2</td>\n      <td>18142.000000</td>\n      <td>14201.0</td>\n      <td>11280.5</td>\n      <td>561.220343</td>\n      <td>62</td>\n      <td>305</td>\n      <td>0.487047</td>\n      <td>0.049727</td>\n      <td>0.030935</td>\n      <td>0.039520</td>\n      <td>0.977736</td>\n      <td>1.134376</td>\n      <td>0.622092</td>\n      <td>0.794733</td>\n      <td>0.782769</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>492</td>\n      <td>83</td>\n      <td>6807.694670</td>\n      <td>4847.5</td>\n      <td>1323.5</td>\n      <td>598.867093</td>\n      <td>52</td>\n      <td>15</td>\n      <td>0.124905</td>\n      <td>0.447584</td>\n      <td>0.087969</td>\n      <td>0.123541</td>\n      <td>1.140181</td>\n      <td>1.214194</td>\n      <td>0.196542</td>\n      <td>0.276019</td>\n      <td>0.712062</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>988</td>\n      <td>5</td>\n      <td>54314.985718</td>\n      <td>33316.0</td>\n      <td>25395.5</td>\n      <td>1076.641697</td>\n      <td>54</td>\n      <td>1504</td>\n      <td>1.197183</td>\n      <td>0.042451</td>\n      <td>0.019822</td>\n      <td>0.032316</td>\n      <td>1.150258</td>\n      <td>1.313623</td>\n      <td>0.466943</td>\n      <td>0.761256</td>\n      <td>0.613385</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imutils import paths\n",
    "from scipy.spatial.distance import minkowski\n",
    "\n",
    "my_data = pd.read_csv(\"800ImagesFeatures.csv\")\n",
    "my_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_val = my_data.drop('labels', axis=1)\n",
    "labels = my_data.labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "135176.3583782622"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate distance between two points\n",
    "\n",
    "def minkowski_distance(a, b, p=1):\n",
    "    # Store the number of dimensions\n",
    "    dim = len(a)\n",
    "    # Set initial distance to 0\n",
    "    distance = 0\n",
    "    # Calculate minkowski distance using parameter p\n",
    "    for d in range(dim):\n",
    "        distance += abs(a[d] - b[d])**p\n",
    "    distance = distance**(1/p)\n",
    "    return distance\n",
    "\n",
    "\n",
    "# Test the function\n",
    "\n",
    "minkowski_distance(a=data_val.iloc[0], b=data_val.iloc[1], p=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Split the data - 75% train, 25% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_val, labels, test_size=0.15,\n",
    "                                                   random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Scale the X data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def knn_predict(X_train, X_test, y_train, y_test, k, p):\n",
    "\n",
    "    # Counter to help with label voting\n",
    "    from collections import Counter\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    # Need output of 1 prediction per test data point\n",
    "    y_hat_test = []\n",
    "\n",
    "    for test_point in X_test:\n",
    "        distances = []\n",
    "\n",
    "        for train_point in X_train:\n",
    "            distance = minkowski(test_point, train_point, p)\n",
    "            # distance = minkowski_distance(test_point, train_point, p=p)\n",
    "            distances.append(distance)\n",
    "\n",
    "        # Store distances in a dataframe\n",
    "        df_dists = pd.DataFrame(data=distances, columns=['dist'],\n",
    "                                index=y_train.index)\n",
    "\n",
    "        # Sort distances, and only consider the k closest points\n",
    "        df_nn = df_dists.sort_values(by=['dist'], axis=0)[:k]\n",
    "\n",
    "        # Create counter object to track the labels of k closest neighbors\n",
    "        counter = Counter(y_train[df_nn.index])\n",
    "\n",
    "        # Get most common label of all the nearest neighbors\n",
    "        prediction = counter.most_common()[0][0]\n",
    "\n",
    "        # Append prediction to output list\n",
    "        y_hat_test.append(prediction)\n",
    "\n",
    "    return y_hat_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "y_hat_test = knn_predict(X_train, X_test, y_train, y_test, k=5, p=1)\n",
    "\n",
    "print(y_hat_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       brush       0.78      0.88      0.83        60\n",
      "        comb       0.87      0.75      0.80        60\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.82      0.82      0.82       120\n",
      "weighted avg       0.82      0.82      0.82       120\n",
      "\n",
      "[[53  7]\n",
      " [15 45]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(accuracy_score(y_test, y_hat_test))\n",
    "print(classification_report(y_test, y_hat_test, target_names=[\"brush\", \"comb\"]))\n",
    "print(confusion_matrix(y_test, y_hat_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from preprocessing import ImageResizer\n",
    "from preprocessing import  SimpleDatasetLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "args = {\n",
    "\t\"dataset\": \"resources\",\n",
    "\t\"neighbors\": 5,\n",
    "\t\"jobs\": -1\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] processed 500/800\n",
      "[INFO] features matrix: 2.3MB\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    "\n",
    "# initialize the image preprocessor, load the dataset from disk,\n",
    "# and reshape the data matrix\n",
    "sp = ImageResizer(32, 32)\n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
    "(data, lbls) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.reshape((data.shape[0], 3072))\n",
    "\n",
    "# show some information on memory consumption of the images\n",
    "print(\"[INFO] features matrix: {:.1f}MB\".format(\n",
    "\tdata.nbytes / (1024 * 1024.0)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brush' 'Comb']\n"
     ]
    }
   ],
   "source": [
    "# encode the labels as integers\n",
    "le = LabelEncoder()\n",
    "lbls = le.fit_transform(lbls)\n",
    "print(le.classes_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1], dtype=int64)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, lbls, test_size=0.10, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "trainY = pd.Series(data=trainY)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Scale the X data\n",
    "scaler = StandardScaler()\n",
    "trainX = scaler.fit_transform(trainX)\n",
    "testX = scaler.transform(testX)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "prediction_2 = knn_predict(trainX, testX, trainY, testY, k=5, p=1)\n",
    "print(prediction_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       brush       0.80      0.80      0.80        41\n",
      "        comb       0.79      0.79      0.79        39\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.80      0.80      0.80        80\n",
      "weighted avg       0.80      0.80      0.80        80\n",
      "\n",
      "[[33  8]\n",
      " [ 8 31]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(testY, prediction_2))\n",
    "print(classification_report(testY, prediction_2, target_names=[\"brush\", \"comb\"]))\n",
    "print(confusion_matrix(testY, prediction_2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f37e0920",
   "language": "python",
   "display_name": "PyCharm (VDK_KammBrueste)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}